{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on 2021\\n\\n@author: Administrator\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on 2021\n",
    "\n",
    "@author: Administrator\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 01 유형(DataSet_01.csv 이용)\n",
    "#\n",
    "# 구분자 : comma(“,”), 4,572 Rows, 5 Columns, UTF-8 인코딩\n",
    "#\n",
    "# 글로벌 전자제품 제조회사에서 효과적인 마케팅 방법을 찾기\n",
    "# 위해서 채널별 마케팅 예산과 매출금액과의 관계를 분석하고자\n",
    "# 한다.\n",
    "# 컬 럼 / 정 의  /   Type\n",
    "# TV   /     TV 마케팅 예산 (억원)  /   Double\n",
    "# Radio / 라디오 마케팅 예산 (억원)  /   Double\n",
    "# Social_Media / 소셜미디어 마케팅 예산 (억원)  / Double\n",
    "# Influencer / 인플루언서 마케팅\n",
    "# (인플루언서의 영향력 크기에 따라 Mega / Macro / Micro /\n",
    "# Nano) / String\n",
    "\n",
    "# SALES / 매출액 / Double\n",
    "# =============================================================================\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "    index     TV      Radio  Social_Media Influencer       Sales\n",
      "0      13    NaN  22.351667      3.031815       Mega  276.165351\n",
      "1      26    NaN  34.111674      4.624148       Nano  342.913372\n",
      "2      46    NaN  34.859637      7.781417       Mega  318.969784\n",
      "3      75    NaN   6.482293      0.866845      Macro   91.177216\n",
      "4      99    NaN   7.635819      1.554146      Macro   56.186730\n",
      "5     119    NaN  30.470485      6.806919      Micro  336.818690\n",
      "6     141    NaN   9.164464      1.096681      Macro   65.259189\n",
      "7     163    NaN  38.118424      6.676611      Micro  328.555184\n",
      "8     182   81.0  26.425422           NaN      Macro  288.649441\n",
      "9     183    NaN   1.287060      0.396179      Macro   56.545293\n",
      "10    184   25.0   0.413849           NaN      Macro   92.357092\n",
      "11    186   73.0  25.340209           NaN       Mega  258.358969\n",
      "12    189   89.0  29.682384           NaN      Macro  320.264397\n",
      "13    192   41.0  13.142657           NaN       Nano  142.626865\n",
      "14    195   34.0  12.660398           NaN       Mega  117.114141\n",
      "15    197   98.0        NaN      6.399730       Nano  345.952838\n",
      "16    200   89.0        NaN      4.535458      Micro  316.725624\n",
      "17    203   22.0        NaN      4.132526      Macro   78.031498\n",
      "18    206   12.0        NaN      1.230026      Micro   50.009210\n",
      "19    208   77.0  25.598379      5.514787       Nano         NaN\n",
      "20    210    NaN  17.007075      5.199635      Macro  208.816382\n",
      "21    214  100.0  36.466753      5.635992       Mega         NaN\n",
      "22    221   74.0  24.220634      0.285898      Micro         NaN\n",
      "23    226   19.0   8.726783      0.497838       Mega         NaN\n",
      "24    231   22.0   6.809752      0.011451      Macro         NaN\n",
      "25    236   27.0   1.384415      2.398129       Nano         NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1. 데이터 세트 내에 총 결측값의 개수는 몇 개인가? (답안 예시) 23\n",
    "# =============================================================================\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data01 = pd.read_csv('./Dataset/Dataset_01.csv')\n",
    "\n",
    "print(data01.isna().sum().sum())\n",
    "\n",
    "# print(data01.isna().sum())\n",
    "\n",
    "# print(data01.columns)\n",
    "\n",
    "# print(data01[['TV', 'Radio', 'Social_Media']].isna().sum().sum())\n",
    "\n",
    "# print(data01.isna().any(axis=1))\n",
    "\n",
    "# print(data01.isna())\n",
    "\n",
    "print(data01[data01.isnull().any(axis=1)].reset_index())\n",
    "\n",
    "\n",
    "# 26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    TV     Radio  Social_Media     Sales\n",
      "TV            1.000000  0.869460      0.528168  0.999497\n",
      "Radio         0.869460  1.000000      0.607452  0.869105\n",
      "Social_Media  0.528168  0.607452      1.000000  0.528906\n",
      "Sales         0.999497  0.869105      0.528906  1.000000\n",
      "0.9995\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 2. TV, Radio, Social Media 등 세 가지 다른 마케팅 채널의 예산과 매출액과의 상관분석을\n",
    "# 통하여 각 채널이 매출에 어느 정도 연관이 있는지 알아보고자 한다.\n",
    "# - 매출액과 가장 강한 상관관계를 가지고 있는 채널의 상관계수를 소수점 5번째\n",
    "# 자리에서 반올림하여 소수점 넷째 자리까지 기술하시오. (답안 예시) 0.1234\n",
    "# =============================================================================\n",
    "\n",
    "print(data01.corr())\n",
    "\n",
    "\n",
    "# print(data01.corr().drop('Sales')['Sales'].abs().max())\n",
    "\n",
    "# print(data01.corr().drop('Sales')['Sales'].abs().idxmax())\n",
    "\n",
    "# print(data01.corr().drop('Sales')['Sales'].abs().nlargest(2).index)\n",
    "\n",
    "# cor_dat = data01.corr().drop('Sales')['Sales'].abs()\n",
    "\n",
    "# print(cor_dat > 0.6)\n",
    "\n",
    "# print(cor_dat)\n",
    "\n",
    "# print(cor_dat.index[cor_dat>0.6])\n",
    "\n",
    "\n",
    "print(round(data01.corr().drop('Sales')['Sales'].abs().max(), 4))\n",
    "\n",
    "# 0.9995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales~TV+Radio+Social_Media\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 1.505e+06\n",
      "Date:                Tue, 15 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        18:00:20   Log-Likelihood:                -11366.\n",
      "No. Observations:                4546   AIC:                         2.274e+04\n",
      "Df Residuals:                    4542   BIC:                         2.277e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       -0.1340      0.103     -1.303      0.193      -0.336       0.068\n",
      "TV               3.5626      0.003   1051.118      0.000       3.556       3.569\n",
      "Radio           -0.0040      0.010     -0.406      0.685      -0.023       0.015\n",
      "Social_Media     0.0050      0.025      0.199      0.842      -0.044       0.054\n",
      "==============================================================================\n",
      "Omnibus:                        0.056   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.972   Jarque-Bera (JB):                0.034\n",
      "Skew:                          -0.001   Prob(JB):                        0.983\n",
      "Kurtosis:                       3.013   Cond. No.                         149.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['TV'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 3. 매출액을 종속변수, TV, Radio, Social Media의 예산을 독립변수로 하여 회귀분석을\n",
    "# 수행하였을 때, 세 개의 독립변수의 회귀계수를 큰 것에서부터 작은 것 순으로\n",
    "# 기술하시오.\n",
    "# - 분석 시 결측치가 포함된 행은 제거한 후 진행하며, 회귀계수는 소수점 넷째 자리\n",
    "# 이하는 버리고 소수점 셋째 자리까지 기술하시오. (답안 예시) 0.123\n",
    "# =============================================================================\n",
    "\n",
    "q2 = data01.dropna()\n",
    "\n",
    "\n",
    "lm = LinearRegression(fit_intercept=False)  # 절편 포함 x\n",
    "lm = LinearRegression(fit_intercept=True)  # 절편 포함\n",
    "\n",
    "var_list = ['TV', 'Radio', 'Social_Media']\n",
    "# lm.fit(q2.drop(columns='Sales'), q2.Sales) # 입력변수 x는 반드시 2차 구조로 입력\n",
    "lm.fit(q2[var_list], q2.Sales)\n",
    "\n",
    "dir(lm)\n",
    "\n",
    "lm.intercept_  # 상수\n",
    "lm.coef_  # 회귀계수\n",
    "\n",
    "form1 = 'Sales~' + '+'.join(var_list)\n",
    "print(form1)\n",
    "lm2 = ols(form1, data=q2).fit()\n",
    "dir(lm2)\n",
    "\n",
    "print(lm2.summary())\n",
    "\n",
    "coef_value = lm2.params.drop('Intercept')\n",
    "coef_value.sort_values(ascending=False).values\n",
    "\n",
    "# 답: ([ 3.562,  0.004, -0.003])\n",
    "\n",
    "lm2.pvalues.index[lm2.pvalues < 0.05]\n",
    "# print(q2['Sales'].shape)\n",
    "# print(q2['Sales'].values)\n",
    "# print(q2['Sales'].values.reshape(-1,1))\n",
    "# print(q2[['Sales']].shape)\n",
    "# print(q2['Sales'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  93,  130,  136,  162,  179,  188,  199,  237,  247,  261,\n",
       "            ...\n",
       "            4405, 4412, 4414, 4419, 4428, 4433, 4448, 4452, 4477, 4569],\n",
       "           dtype='int64', length=219)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2.index[lm2.outlier_test()['unadj_p'] < 0.05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = q2[var_list]\n",
    "y = q2.Sales\n",
    "\n",
    "lm3 = OLS(y, x).fit()\n",
    "lm3.summary()\n",
    "\n",
    "xx = add_constant(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Social_Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.566231</td>\n",
       "      <td>2.907983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.237765</td>\n",
       "      <td>2.409567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.886446</td>\n",
       "      <td>2.913410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>30.020028</td>\n",
       "      <td>6.922304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.437408</td>\n",
       "      <td>1.405998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.472360</td>\n",
       "      <td>0.717090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20.610685</td>\n",
       "      <td>6.545573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.800072</td>\n",
       "      <td>5.096192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>17.534640</td>\n",
       "      <td>1.940873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.966688</td>\n",
       "      <td>5.046548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4546 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      const    TV      Radio  Social_Media\n",
       "0       1.0  16.0   6.566231      2.907983\n",
       "1       1.0  13.0   9.237765      2.409567\n",
       "2       1.0  41.0  15.886446      2.913410\n",
       "3       1.0  83.0  30.020028      6.922304\n",
       "4       1.0  15.0   8.437408      1.405998\n",
       "...     ...   ...        ...           ...\n",
       "4567    1.0  26.0   4.472360      0.717090\n",
       "4568    1.0  71.0  20.610685      6.545573\n",
       "4569    1.0  44.0  19.800072      5.096192\n",
       "4570    1.0  71.0  17.534640      1.940873\n",
       "4571    1.0  42.0  15.966688      5.046548\n",
       "\n",
       "[4546 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared (uncentered):</th>      <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>7.951e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Feb 2022</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:00:28</td>     <th>  Log-Likelihood:    </th>          <td> -11367.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4546</td>      <th>  AIC:               </th>          <td>2.274e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4543</td>      <th>  BIC:               </th>          <td>2.276e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>           <td>    3.5609</td> <td>    0.003</td> <td> 1133.941</td> <td> 0.000</td> <td>    3.555</td> <td>    3.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>        <td>   -0.0039</td> <td>    0.010</td> <td>   -0.400</td> <td> 0.689</td> <td>   -0.023</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_Media</th> <td>   -0.0013</td> <td>    0.024</td> <td>   -0.054</td> <td> 0.957</td> <td>   -0.049</td> <td>    0.047</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.061</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.970</td> <th>  Jarque-Bera (JB):  </th> <td>   0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.001</td> <th>  Prob(JB):          </th> <td>   0.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.014</td> <th>  Cond. No.          </th> <td>    35.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                  Sales   R-squared (uncentered):                   1.000\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              1.000\n",
       "Method:                 Least Squares   F-statistic:                          7.951e+06\n",
       "Date:                Tue, 15 Feb 2022   Prob (F-statistic):                        0.00\n",
       "Time:                        18:00:28   Log-Likelihood:                         -11367.\n",
       "No. Observations:                4546   AIC:                                  2.274e+04\n",
       "Df Residuals:                    4543   BIC:                                  2.276e+04\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "TV               3.5609      0.003   1133.941      0.000       3.555       3.567\n",
       "Radio           -0.0039      0.010     -0.400      0.689      -0.023       0.015\n",
       "Social_Media    -0.0013      0.024     -0.054      0.957      -0.049       0.047\n",
       "==============================================================================\n",
       "Omnibus:                        0.061   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.970   Jarque-Bera (JB):                0.038\n",
       "Skew:                          -0.001   Prob(JB):                        0.981\n",
       "Kurtosis:                       3.014   Cond. No.                         35.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.999</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.505e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Feb 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:00:28</td>     <th>  Log-Likelihood:    </th> <td> -11366.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4546</td>      <th>  AIC:               </th> <td>2.274e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4542</td>      <th>  BIC:               </th> <td>2.277e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   -0.1340</td> <td>    0.103</td> <td>   -1.303</td> <td> 0.193</td> <td>   -0.336</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>           <td>    3.5626</td> <td>    0.003</td> <td> 1051.118</td> <td> 0.000</td> <td>    3.556</td> <td>    3.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Radio</th>        <td>   -0.0040</td> <td>    0.010</td> <td>   -0.406</td> <td> 0.685</td> <td>   -0.023</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_Media</th> <td>    0.0050</td> <td>    0.025</td> <td>    0.199</td> <td> 0.842</td> <td>   -0.044</td> <td>    0.054</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.056</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.972</td> <th>  Jarque-Bera (JB):  </th> <td>   0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.001</td> <th>  Prob(JB):          </th> <td>   0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.013</td> <th>  Cond. No.          </th> <td>    149.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.999\n",
       "Model:                            OLS   Adj. R-squared:                  0.999\n",
       "Method:                 Least Squares   F-statistic:                 1.505e+06\n",
       "Date:                Tue, 15 Feb 2022   Prob (F-statistic):               0.00\n",
       "Time:                        18:00:28   Log-Likelihood:                -11366.\n",
       "No. Observations:                4546   AIC:                         2.274e+04\n",
       "Df Residuals:                    4542   BIC:                         2.277e+04\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           -0.1340      0.103     -1.303      0.193      -0.336       0.068\n",
       "TV               3.5626      0.003   1051.118      0.000       3.556       3.569\n",
       "Radio           -0.0040      0.010     -0.406      0.685      -0.023       0.015\n",
       "Social_Media     0.0050      0.025      0.199      0.842      -0.044       0.054\n",
       "==============================================================================\n",
       "Omnibus:                        0.056   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.972   Jarque-Bera (JB):                0.034\n",
       "Skew:                          -0.001   Prob(JB):                        0.983\n",
       "Kurtosis:                       3.013   Cond. No.                         149.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm4 = OLS(y, xx).fit()\n",
    "lm4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 02 유형(DataSet_02.csv 이용)\n",
    "# 구분자 : comma(“,”), 200 Rows, 6 Columns, UTF-8 인코딩\n",
    "\n",
    "# 환자의 상태와 그에 따라 처방된 약에 대한 정보를 분석하고자한다\n",
    "#\n",
    "# 컬 럼 / 정 의  / Type\n",
    "# Age  / 연령 / Integer\n",
    "# Sex / 성별 / String\n",
    "# BP / 혈압 레벨 / String\n",
    "# Cholesterol / 콜레스테롤 레벨 /  String\n",
    "# Na_to_k / 혈액 내 칼륨에 대비한 나트륨 비율 / Double\n",
    "# Drug / Drug Type / String\n",
    "# =============================================================================\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Sex    BP Cholesterol  Na_to_K   Drug\n",
      "0   23   F  HIGH        HIGH   25.355  DrugY\n",
      "1   47   M   LOW        HIGH   13.093  drugC\n",
      "(200, 6)\n"
     ]
    }
   ],
   "source": [
    "data02 = pd.read_csv('./Dataset/Dataset_02.csv')\n",
    "print(data02.head(2))\n",
    "print(data02.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1.해당 데이터에 대한 EDA를 수행하고, 여성으로 혈압이 High, Cholesterol이 Normal인\n",
    "# 환자의 전체에 대비한 비율이 얼마인지 소수점 네 번째 자리에서 반올림하여 소수점 셋째\n",
    "# 자리까지 기술하시오. (답안 예시) 0.123\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data02.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data02[['Sex', 'BP', 'Cholesterol']].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.105"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1[('F', 'HIGH', 'NORMAL')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_1 = pd.crosstab(index=[data02['Sex'], data02['BP']],\n",
    "                   columns=data02['Cholesterol'], normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>HIGH</th>\n",
       "      <th>NORMAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">F</th>\n",
       "      <th>HIGH</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOW</th>\n",
       "      <td>0.070</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORMAL</th>\n",
       "      <td>0.090</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">M</th>\n",
       "      <th>HIGH</th>\n",
       "      <td>0.090</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOW</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORMAL</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cholesterol   HIGH  NORMAL\n",
       "Sex BP                    \n",
       "F   HIGH     0.085   0.105\n",
       "    LOW      0.070   0.070\n",
       "    NORMAL   0.090   0.060\n",
       "M   HIGH     0.090   0.105\n",
       "    LOW      0.085   0.095\n",
       "    NORMAL   0.095   0.050"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 2. Age, Sex, BP, Cholesterol 및 Na_to_k 값이 Drug 타입에 영향을 미치는지 확인하기\n",
    "# 위하여 아래와 같이 데이터를 변환하고 분석을 수행하시오.\n",
    "# - Age_gr 컬럼을 만들고, Age가 20 미만은 ‘10’, 20부터 30 미만은 ‘20’, 30부터 40 미만은\n",
    "# ‘30’, 40부터 50 미만은 ‘40’, 50부터 60 미만은 ‘50’, 60이상은 ‘60’으로 변환하시오.\n",
    "# - Na_K_gr 컬럼을 만들고 Na_to_k 값이 10이하는 ‘Lv1’, 20이하는 ‘Lv2’, 30이하는 ‘Lv3’, 30\n",
    "# 초과는 ‘Lv4’로 변환하시오.\n",
    "# - Sex, BP, Cholesterol, Age_gr, Na_K_gr이 Drug 변수와 영향이 있는지 독립성 검정을\n",
    "# 수행하시오.\n",
    "# - 검정 수행 결과, Drug 타입과 연관성이 있는 변수는 몇 개인가? 연관성이 있는 변수\n",
    "# 가운데 가장 큰 p-value를 찾아 소수점 여섯 번째 자리 이하는 버리고 소수점 다섯\n",
    "# 번째 자리까지 기술하시오.\n",
    "# (답안 예시) 3, 1.23456\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = data02.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2['Age_gr'] = np.where(q2.Age < 20, 10,\n",
    "                        np.where(q2.Age < 30, 20,\n",
    "                                 np.where(q2.Age < 40, 30,\n",
    "                                          np.where(q2.Age < 50, 40,\n",
    "                                                   np.where(q2.Age < 60, 50, 60)))))\n",
    "\n",
    "q2['Na_K_gr'] = np.where(q2.Na_to_K <= 10, 'Lv1',\n",
    "                         np.where(q2.Na_to_K <= 20, 'Lv2',\n",
    "                                  np.where(q2.Na_to_K <= 30, 'Lv3', 'Lv4')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.crosstab(index=q2.Sex, columns=q2.Drug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_out = chi2_contingency(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7138369773987128"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.119248418109203,\n",
       " 0.7138369773987128,\n",
       " 4,\n",
       " array([[43.68, 11.04,  7.68,  7.68, 25.92],\n",
       "        [47.32, 11.96,  8.32,  8.32, 28.08]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug', 'Age_gr',\n",
       "       'Na_K_gr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['Sex', 'BP', 'Cholesterol', 'Age_gr', 'Na_K_gr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_out = []\n",
    "for i in var_list:\n",
    "    tab = pd.crosstab(index=q2[i], columns=q2.Drug)\n",
    "    q2_out0 = chi2_contingency(tab)\n",
    "    pvalue = q2_out0[1]\n",
    "    q2_out.append([i, pvalue])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Sex', 0.7138369773987128],\n",
       " ['BP', 5.0417334144665895e-27],\n",
       " ['Cholesterol', 0.0005962588389856497],\n",
       " ['Age_gr', 0.0007010113024729462],\n",
       " ['Na_K_gr', 1.1254641594413981e-14]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_out = pd.DataFrame(q2_out, columns=['var', 'pvalue'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>7.138370e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BP</td>\n",
       "      <td>5.041733e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cholesterol</td>\n",
       "      <td>5.962588e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age_gr</td>\n",
       "      <td>7.010113e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Na_K_gr</td>\n",
       "      <td>1.125464e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           var        pvalue\n",
       "0          Sex  7.138370e-01\n",
       "1           BP  5.041733e-27\n",
       "2  Cholesterol  5.962588e-04\n",
       "3       Age_gr  7.010113e-04\n",
       "4      Na_K_gr  1.125464e-14"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BP</td>\n",
       "      <td>5.041733e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cholesterol</td>\n",
       "      <td>5.962588e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age_gr</td>\n",
       "      <td>7.010113e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Na_K_gr</td>\n",
       "      <td>1.125464e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           var        pvalue\n",
       "1           BP  5.041733e-27\n",
       "2  Cholesterol  5.962588e-04\n",
       "3       Age_gr  7.010113e-04\n",
       "4      Na_K_gr  1.125464e-14"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out[q2_out.pvalue < 0.05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_out2 = q2_out[q2_out.pvalue < 0.05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out2.pvalue.idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = q2_out2.pvalue.idxmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var       Na_K_gr\n",
       "pvalue        0.0\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out2.iloc[idx, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007010113024729462"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out2.pvalue.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.floor(q2_out2.pvalue.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(q2_out2.pvalue.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(q2_out2.pvalue.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00070'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(np.floor(a*100000)/100000, '.5f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.00070\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 3.Sex, BP, Cholesterol 등 세 개의 변수를 다음과 같이 변환하고 의사결정나무를 이용한\n",
    "# 분석을 수행하시오.\n",
    "# - Sex는 M을 0, F를 1로 변환하여 Sex_cd 변수 생성\n",
    "# - BP는 LOW는 0, NORMAL은 1 그리고 HIGH는 2로 변환하여 BP_cd 변수 생성\n",
    "# - Cholesterol은 NORMAL은 0, HIGH는 1로 변환하여 Ch_cd 생성\n",
    "# - Age, Na_to_k, Sex_cd, BP_cd, Ch_cd를 Feature로, Drug을 Label로 하여 의사결정나무를\n",
    "# 수행하고 Root Node의 split feature와 split value를 기술하시오.\n",
    "# 이 때 split value는 소수점 셋째 자리까지 반올림하여 기술하시오. (답안 예시) Age,\n",
    "# 12.345\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 03 유형(DataSet_03.csv 이용)\n",
    "#\n",
    "# 구분자 : comma(“,”), 5,001 Rows, 8 Columns, UTF-8 인코딩\n",
    "# 안경 체인을 운영하고 있는 한 회사에서 고객 사진을 바탕으로 안경의 사이즈를\n",
    "# 맞춤 제작하는 비즈니스를 기획하고 있다. 우선 데이터만으로 고객의 성별을\n",
    "# 파악하는 것이 가능할 지를 연구하고자 한다.\n",
    "#\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# long_hair / 머리카락 길이 (0 – 길지 않은 경우 / 1 – 긴\n",
    "# 경우) / Integer\n",
    "# forehead_width_cm / 이마의 폭 (cm) / Double\n",
    "# forehead_height_cm / 이마의 높이 (cm) / Double\n",
    "# nose_wide / 코의 넓이 (0 – 넓지 않은 경우 / 1 – 넓은 경우) / Integer\n",
    "# nose_long / 코의 길이 (0 – 길지 않은 경우 / 1 – 긴 경우) / Integer\n",
    "# lips_thin / 입술이 얇은지 여부 0 – 얇지 않은 경우 / 1 –\n",
    "# 얇은 경우) / Integer\n",
    "# distance_nose_to_lip_long / 인중의 길이(0 – 인중이 짧은 경우 / 1 – 인중이\n",
    "# 긴 경우) / Integer\n",
    "# gender / 성별 (Female / Male) / String\n",
    "# =============================================================================\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data03 = pd.read_csv('./Dataset/Dataset_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1.이마의 폭(forehead_width_cm)과 높이(forehead_height_cm) 사이의\n",
    "# 비율(forehead_ratio)에 대해서 평균으로부터 3 표준편차 밖의 경우를 이상치로\n",
    "# 정의할 때, 이상치에 해당하는 데이터는 몇 개인가? (답안 예시) 10\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data03.copy()\n",
    "q1['forehead_ratio'] = q1['forehead_width_cm']/q1['forehead_height_cm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbar = q1['forehead_ratio'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = q1['forehead_ratio'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ub = xbar + 3 * std\n",
    "lb = xbar - 3 * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_hair</th>\n",
       "      <th>forehead_width_cm</th>\n",
       "      <th>forehead_height_cm</th>\n",
       "      <th>nose_wide</th>\n",
       "      <th>nose_long</th>\n",
       "      <th>lips_thin</th>\n",
       "      <th>distance_nose_to_lip_long</th>\n",
       "      <th>gender</th>\n",
       "      <th>forehead_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>1</td>\n",
       "      <td>15.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>1</td>\n",
       "      <td>15.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.039216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
       "1641          1               15.5                 5.1          1          1   \n",
       "1817          1               15.5                 5.1          1          0   \n",
       "4948          0               15.5                 5.1          1          1   \n",
       "\n",
       "      lips_thin  distance_nose_to_lip_long gender  forehead_ratio  \n",
       "1641          1                          1   Male        3.039216  \n",
       "1817          1                          1   Male        3.039216  \n",
       "4948          1                          1   Male        3.039216  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1[(q1['forehead_ratio'] > ub) | (q1['forehead_ratio'] < lb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답 : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 2.성별에 따라 forehead_ratio 평균에 차이가 있는지 적절한 통계 검정을 수행하시오.\n",
    "# - 검정은 이분산을 가정하고 수행한다.\n",
    "# - 검정통계량의 추정치는 절대값을 취한 후 소수점 셋째 자리까지 반올림하여\n",
    "# 기술하시오.\n",
    "# - 신뢰수준 99%에서 양측 검정을 수행하고 결과는 귀무가설 기각의 경우 Y로, 그렇지\n",
    "# 않을 경우 N으로 답하시오. (답안 예시) 1.234, Y\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttest_ind  독립\n",
    "# ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_m = q1[q1.gender == 'Male']['forehead_ratio']\n",
    "g_f = q1[q1.gender == 'Female']['forehead_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.9994984197511543, pvalue=0.0027186702390657176)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out = ttest_ind(g_m, g_f, equal_var=False)\n",
    "q2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_out.pvalue * 2 < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.999"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(q2_out.statistic, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답: Y, 2.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 3.주어진 데이터를 사용하여 성별을 구분할 수 있는지 로지스틱 회귀분석을 적용하여\n",
    "# 알아 보고자 한다.\n",
    "# - 데이터를 7대 3으로 나누어 각각 Train과 Test set로 사용한다. 이 때 seed는 123으로\n",
    "# 한다.\n",
    "# - 원 데이터에 있는 7개의 변수만 Feature로 사용하고 gender를 label로 사용한다.\n",
    "# (forehead_ratio는 사용하지 않음)\n",
    "# - 로지스틱 회귀분석 예측 함수와 Test dataset를 사용하여 예측을 수행하고 정확도를\n",
    "# 평가한다. 이 때 임계값은 0.5를 사용한다.\n",
    "# - Male의 Precision 값을 소수점 둘째 자리까지 반올림하여 기술하시오. (답안 예시)\n",
    "# 0.12\n",
    "#\n",
    "#\n",
    "# (참고)\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import metrics\n",
    "# train_test_split 의 random_state = 123\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 04 유형(DataSet_04.csv 이용)\n",
    "#\n",
    "# 구분자 : comma(“,”), 6,718 Rows, 4 Columns, UTF-8 인코딩\n",
    "\n",
    "# 한국인의 식생활 변화가 건강에 미치는 영향을 분석하기에 앞서 육류\n",
    "# 소비량에 대한 분석을 하려고 한다. 확보한 데이터는 세계 각국의 1인당\n",
    "# 육류 소비량 데이터로 아래와 같은 내용을 담고 있다.\n",
    "\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# LOCATION / 국가명 / String\n",
    "# SUBJECT / 육류 종류 (BEEF / PIG / POULTRY / SHEEP) / String\n",
    "# TIME / 연도 (1990 ~ 2026) / Integer\n",
    "# Value / 1인당 육류 소비량 (KG) / Double\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "# (참고)\n",
    "# #1\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# #2\n",
    "# from scipy.stats import ttest_rel\n",
    "# #3\n",
    "# from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1.한국인의 1인당 육류 소비량이 해가 갈수록 증가하는 것으로 보여 상관분석을 통하여\n",
    "# 확인하려고 한다.\n",
    "# - 데이터 파일로부터 한국 데이터만 추출한다. 한국은 KOR로 표기되어 있다.\n",
    "# - 년도별 육류 소비량 합계를 구하여 TIME과 Value간의 상관분석을 수행하고\n",
    "# 상관계수를 소수점 셋째 자리에서 반올림하여 소수점 둘째 자리까지만 기술하시오.\n",
    "# (답안 예시) 0.55\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 2. 한국 인근 국가 가운데 식생의 유사성이 상대적으로 높은 일본(JPN)과 비교하여, 연도별\n",
    "# 소비량에 평균 차이가 있는지 분석하고자 한다.\n",
    "# - 두 국가의 육류별 소비량을 연도기준으로 비교하는 대응표본 t 검정을 수행하시오.\n",
    "# - 두 국가 간의 연도별 소비량 차이가 없는 것으로 판단할 수 있는 육류 종류를 모두\n",
    "# 적으시오. (알파벳 순서) (답안 예시) BEEF, PIG, POULTRY, SHEEP\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 3.(한국만 포함한 데이터에서) Time을 독립변수로, Value를 종속변수로 하여 육류\n",
    "# 종류(SUBJECT) 별로 회귀분석을 수행하였을 때, 가장 높은 결정계수를 가진 모델의\n",
    "# 학습오차 중 MAPE를 반올림하여 소수점 둘째 자리까지 기술하시오. (답안 예시) 21.12\n",
    "# (MAPE : Mean Absolute Percentage Error, 평균 절대 백분율 오차)\n",
    "# (MAPE = Σ ( | y - y ̂ | / y ) * 100/n ))\n",
    "#\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# # 문제 05 유형(DataSet_05.csv 이용)\n",
    "#\n",
    "# 구분자 : comma(“,”), 8,068 Rows, 12 Columns, UTF-8 인코딩\n",
    "#\n",
    "# A자동차 회사는 신규 진입하는 시장에 기존 모델을 판매하기 위한 마케팅 전략을\n",
    "# 세우려고 한다. 기존 시장과 고객 특성이 유사하다는 전제 하에 기존 고객을 세분화하여\n",
    "# 각 그룹의 특징을 파악하고, 이를 이용하여 신규 진입 시장의 마케팅 계획을\n",
    "# 수립하고자 한다. 다음은 기존 시장 고객에 대한 데이터이다.\n",
    "#\n",
    "\n",
    "# 컬 럼 / 정 의 / Type\n",
    "# ID / 고유 식별자 / Double\n",
    "# Age / 나이 / Double\n",
    "# Age_gr / 나이 그룹 (10/20/30/40/50/60/70) / Double\n",
    "# Gender / 성별 (여성 : 0 / 남성 : 1) / Double\n",
    "# Work_Experience / 취업 연수 (0 ~ 14) / Double\n",
    "# Family_Size / 가족 규모 (1 ~ 9) / Double\n",
    "# Ever_Married / 결혼 여부 (Unknown : 0 / No : 1 / Yes : 2) / Double\n",
    "# Graduated / 재학 중인지 여부 / Double\n",
    "# Profession / 직업 (Unknown : 0 / Artist ~ Marketing 등 9개) / Double\n",
    "# Spending_Score / 소비 점수 (Average : 0 / High : 1 / Low : 2) / Double\n",
    "# Var_1 / 내용이 알려지지 않은 고객 분류 코드 (0 ~ 7) / Double\n",
    "# Segmentation / 고객 세분화 결과 (A ~ D) / String\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# (참고)\n",
    "# 1\n",
    "# import pandas as pd\n",
    "# #2\n",
    "# from scipy.stats import chi2_contingency\n",
    "# #3\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import metrics\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.tree import export_graphviz\n",
    "# import pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1.위의 표에 표시된 데이터 타입에 맞도록 전처리를 수행하였을 때, 데이터 파일 내에\n",
    "# 존재하는 결측값은 모두 몇 개인가? 숫자형 데이터와 문자열 데이터의 결측값을\n",
    "# 모두 더하여 답하시오.\n",
    "# (String 타입 변수의 경우 White Space(Blank)를 결측으로 처리한다) (답안 예시) 123\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 2.이어지는 분석을 위해 결측값을 모두 삭제한다. 그리고, 성별이 세분화(Segmentation)에\n",
    "# 영향을 미치는지 독립성 검정을 수행한다. 수행 결과, p-value를 반올림하여 소수점\n",
    "# 넷째 자리까지 쓰고, 귀무가설을 기각하면 Y로, 기각할 수 없으면 N으로 기술하시오.\n",
    "# (답안 예시) 0.2345, N\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 3.Segmentation 값이 A 또는 D인 데이터만 사용하여 의사결정 나무 기법으로 분류\n",
    "# 정확도를\n",
    "# 측정해 본다.\n",
    "# - 결측치가 포함된 행은 제거한 후 진행하시오.\n",
    "# - Train대 Test 7대3으로 데이터를 분리한다. (Seed = 123)\n",
    "# - Train 데이터를 사용하여 의사결정나무 학습을 수행하고, Test 데이터로 평가를\n",
    "# 수행한다.\n",
    "# - 의사결정나무 학습 시, 다음과 같이 설정하시오:\n",
    "# • Feature: Age_gr, Gender, Work_Experience, Family_Size,\n",
    "#             Ever_Married, Graduated, Spending_Score\n",
    "# • Label : Segmentation\n",
    "# • Parameter : Gini / Max Depth = 7 / Seed = 123\n",
    "# 이 때 전체 정확도(Accuracy)를 소수점 셋째 자리 이하는 버리고 소수점 둘째자리까지\n",
    "# 기술하시오.\n",
    "# (답안 예시) 0.12\n",
    "# =============================================================================\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
